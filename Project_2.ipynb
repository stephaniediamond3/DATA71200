{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stephaniediamond3/DATA71200/blob/main/Project_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgXzIRgN-o1j"
      },
      "source": [
        "# Step 1: Load your data, including testing/training split from Project 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlVKXIznBTvS"
      },
      "source": [
        "The full natality file from the CDC is massive and takes 15-30 minutes to download, so I saved the version from Project 1 that just contains the columns of interest from the dataset and the columns I created. I'm using pyarrow to read it in."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5_DVR3H-y25",
        "outputId": "26e22659-bbaf-4081-fd17-f6316332d311"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.12/dist-packages (18.1.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown) (4.13.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from gdown) (3.20.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.12/dist-packages (from gdown) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2025.11.12)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1rzpkN4pT8HUgLq8HaXOKBFVGXfSe9FVq\n",
            "To: /content/natality2024_trimmed_clean.parquet\n",
            "100%|██████████| 27.0M/27.0M [00:00<00:00, 118MB/s]\n"
          ]
        }
      ],
      "source": [
        "!pip install gdown pyarrow\n",
        "\n",
        "import gdown\n",
        "import pandas as pd\n",
        "\n",
        "# file URL (should be acessible to anyone with the link):\n",
        "# https://drive.google.com/file/d/1rzpkN4pT8HUgLq8HaXOKBFVGXfSe9FVq/view?usp=sharing\n",
        "file_id = \"1rzpkN4pT8HUgLq8HaXOKBFVGXfSe9FVq\"\n",
        "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "\n",
        "gdown.download(url, \"natality2024_trimmed_clean.parquet\", quiet=False)\n",
        "\n",
        "df = pd.read_parquet(\"natality2024_trimmed_clean.parquet\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Iobkx8gC9Td"
      },
      "source": [
        "### Testing/training split from Project 1:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mxiZDXmByTt",
        "outputId": "e0b32cb6-99ad-4d0e-b7ad-beba5c647114"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2538450, 29) (1087908, 29)\n",
            "smm\n",
            "0.0    0.984658\n",
            "1.0    0.015342\n",
            "Name: proportion, dtype: float64\n",
            "smm\n",
            "0.0    0.984658\n",
            "1.0    0.015342\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Prep\n",
        "df_model = df.dropna(subset=[\"smm\"]).copy()\n",
        "\n",
        "mm_cols = [\"mm_mtr\",\"mm_plac\",\"mm_rupt\",\"mm_uhyst\",\"mm_aicu\"]\n",
        "y = df_model[\"smm\"]\n",
        "X = df_model.drop(columns=[\"smm\"] + mm_cols)\n",
        "\n",
        "# Train/test split with stratification to preserve SMM balance\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, random_state=66, test_size=0.3, stratify=y\n",
        ")\n",
        "\n",
        "# Check shapes/balance\n",
        "print(X_train.shape, X_test.shape)\n",
        "print(y_train.value_counts(normalize=True))\n",
        "print(y_test.value_counts(normalize=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLq9GGShDek2"
      },
      "source": [
        "I reproduced the 70/30 stratified train/test split from Project 1 using the same random state (66). The training and testing sets have similar Severe Maternal Morbididty (SMM) prevalence (~1.5%), confirming that the split is balanced on the outcome."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iy741-Rndc_1"
      },
      "source": [
        "### Cleaning from Project 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1XNuSOEGlod"
      },
      "source": [
        "I apply the same cleaning strategy as in Project 1: two risk factor variables with very high missingness (asst. reproductive technology, and fertility enhancing drugs ) are dropped, and remaining missing values (primarily in binary risk factor variables with ~0.01% missingness) are imputed using the most frequent category (mode)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "j0WDmE7JD95J",
        "outputId": "c8bac4d4-b4ce-4d5d-9a1e-9fd3312fb704"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>rf_pdiab</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rf_gdiab</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rf_phype</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rf_ghype</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rf_ehype</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rf_ppterm</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rf_inftr</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rf_cesar</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rf_cesarn</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>no_risks</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>meduc</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>wic</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pay_rec</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mracehisp</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mhisp_r</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "rf_pdiab     0\n",
              "rf_gdiab     0\n",
              "rf_phype     0\n",
              "rf_ghype     0\n",
              "rf_ehype     0\n",
              "rf_ppterm    0\n",
              "rf_inftr     0\n",
              "rf_cesar     0\n",
              "rf_cesarn    0\n",
              "no_risks     0\n",
              "meduc        0\n",
              "wic          0\n",
              "pay_rec      0\n",
              "mracehisp    0\n",
              "mhisp_r      0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Drop very incomplete variables\n",
        "drop_cols = [\"rf_artec\", \"rf_fedrg\"]\n",
        "X_train = X_train.drop(columns=drop_cols, errors=\"ignore\")\n",
        "X_test = X_test.drop(columns=drop_cols, errors=\"ignore\")\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "#Since all vars w ~.01% missing are Y/N binaries, will impute mode\n",
        "imp_mode = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
        "imp_mode.fit(X_train)\n",
        "X_train_new = imp_mode.transform(X_train)\n",
        "X_test_new = imp_mode.transform(X_test)\n",
        "\n",
        "X_train = pd.DataFrame(X_train_new, columns=X_train.columns)\n",
        "X_test = pd.DataFrame(X_test_new, columns=X_test.columns)\n",
        "\n",
        "X_train.isna().sum().sort_values(ascending=False).head(15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B84hwLejG2-S"
      },
      "source": [
        "# Step 2: Prepare your data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFkx3qMsHZT3"
      },
      "outputs": [],
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
        "\n",
        "# Numeric features for Scaling\n",
        "numeric_features = [\n",
        "    \"mager\", #maternal age\n",
        "    \"rf_cesarn\", #Number of Previous Cesareans\n",
        "    \"priorlive\", #Prior Births Now Living\n",
        "    \"priordead\", #Prior Births Now Dead\n",
        "    \"priorterm\", #Prior Other Terminations\n",
        "]\n",
        "\n",
        "# Ordinal features for ordinal encoding\n",
        "ordinal_features = [\n",
        "    \"meduc\", #Mother’s Education\n",
        "    \"bmi_r\", #Body Mass Index Recode\n",
        "    \"precare5\", #Month Prenatal Care Began Recode\n",
        "    \"gestrec10\", #Combined Gestation Recode 10\n",
        "    \"cig0_r\", #Cigarettes Before Pregnancy Recode\n",
        "    \"dplural\", #Plurality Recode (twin, triplet, etc)\n",
        "]\n",
        "\n",
        "#categorical deatures for OHE\n",
        "nominal_categorical_features = [\n",
        "    \"pay_rec\", #Payment Recode (Medicaid, Private Insurance, etc)\n",
        "    \"mracehisp\", #Mother’s Race/Hispanic Origin\n",
        "    \"mhisp_r\", #Mother’s Hispanic Origin Recode\n",
        "    \"mrace6\", #Mother’s Race Recode 6\n",
        "]\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"scaling\", StandardScaler(), numeric_features),\n",
        "        (\"ordinal\", OrdinalEncoder(), ordinal_features),\n",
        "        (\"onehot\", OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\"), nominal_categorical_features),\n",
        "    ],\n",
        "    remainder=\"passthrough\" #Already binary (risk factors, risk composite, WIC)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBJiudOadwdO"
      },
      "source": [
        "To prepare my variables for machine learning, I converted all predictors into appropriate numeric, ordinal, or one-hot encoded forms based on their underlying structure. I grouped each feature by type and applied the corresponding transformation using a ColumnTransformer.\n",
        "\n",
        "*   I standardize the numeric features (maternal age, number of previous cesareans, and the counts of prior live births, prior deaths, and prior terminations) with StandardScaler so they share a comparable scale.\n",
        "*   I encode the ordinal categorical features (maternal education, BMI category, month prenatal care began, gestational age category, cigarette use before pregnancy, and plurality) with OrdinalEncoder. These variables follow a meaningful order, so I preserve their rank structure.\n",
        "*   I one-hot encode the nominal categorical features (payment method at delivery, mother’s race/Hispanic origin, mother’s Hispanic origin recode, and the six-category maternal race recode) with OneHotEncoder. These variables represent categories without an inherent ranking, so I convert each category into its own indicator column.\n",
        "*   I leave the binary variables unchanged (the individual medical risk factors, the composite “no risks” indicator, and WIC indicator). These variables already function as 0/1 categorical indicators, so they do not require further transformation.\n",
        "\n",
        "\n",
        "This preprocessing setup ensures that each feature reflects its underlying structure and enters the modeling stage in a consistent format that supports the supervised learning algorithms I apply in later steps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-Jq6UbgG7kq"
      },
      "source": [
        "# Step 3: Examine target attribute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 656
        },
        "id": "-Rxlnow4Hbcd",
        "outputId": "a3a87ed0-f6ad-4ee0-8aca-f57983dccd62"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>proportion</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>smm</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0.0</th>\n",
              "      <td>0.984658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1.0</th>\n",
              "      <td>0.015342</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ],
            "text/plain": [
              "smm\n",
              "0.0    0.984658\n",
              "1.0    0.015342\n",
              "Name: proportion, dtype: float64"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# distribution of SMM in the training set\n",
        "y_train.value_counts().plot(kind=\"bar\")\n",
        "plt.title(\"Distribution of Severe Maternal Morbidity (SMM) in the Training Set\")\n",
        "plt.xlabel(\"SMM (0 = No Morbidity, 1 = Any Morbidity)\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()\n",
        "\n",
        "# proportions\n",
        "y_train.value_counts(normalize=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPWsAj3rEXtn"
      },
      "source": [
        "SMM is a binary indicator of whether a delivery involved any severe maternal morbidity event. Because these events are uncommon in the population, I expect the positive class to be rare.\n",
        "\n",
        "The bar plot and proportions below confirm that the training data is highly imbalanced, with a small share of deliveries coded as SMM and the majority coded as non-SMM. This distribution is not Gaussian or uniform; instead, it reflects a rare-event binary outcome.\n",
        "\n",
        "This pattern has direct implications for model evaluation. A model could achieve high accuracy by predicting “no SMM” for every case, so accuracy alone does not provide meaningful insight. Metrics such as precision, recall, and F1 offer a more appropriate view of performance for this type of imbalanced outcome."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uM1zQsssHB90"
      },
      "source": [
        "# Step 4: Select two supervised learning algorithms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cy-zszV8BL7s"
      },
      "source": [
        "### Algorithm 1: Linear Model (logistic regression)\n",
        "\n",
        "I will use logistic regression because it handles imbalanced binary outcomes more effectively than other options in the first half of the list, such as K-Nearest Neighbors. Logistic regression also provides a strong baseline model that helps anchor the comparison to more flexible algorithms.\n",
        "\n",
        "### Algorithm 2: Random Forest\n",
        "\n",
        "I will use a Random Forest classifier because it captures nonlinear relationships, interactions, and complex patterns across maternal, demographic, and clinical predictors. Random Forests handle categorical expansions well and are generally robust to class imbalance. Comparing logistic regression to a Random Forest allows me to evaluate the trade-offs between a linear, interpretable model and a flexible ensemble method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Smir9ujZHPNH"
      },
      "source": [
        "# Step 5: For each of the selected models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UlgcJWyHc9g"
      },
      "source": [
        "### Run with the default parameters, training on your training set and testing on your testing set. Calculate precision, recall, and F1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIQ9muM-9m0v"
      },
      "source": [
        "Logistic Regression:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eJBkL_3HleH",
        "outputId": "49ada985-9ff0-4702-cbec-4f7af517bb7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set score: 0.985\n",
            "Test set score: 0.985\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      1.00      0.99   1071217\n",
            "         1.0       0.00      0.00      0.00     16691\n",
            "\n",
            "    accuracy                           0.98   1087908\n",
            "   macro avg       0.49      0.50      0.50   1087908\n",
            "weighted avg       0.97      0.98      0.98   1087908\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# apply preprocessing from Step 2\n",
        "X_train_processed = preprocessor.fit_transform(X_train)\n",
        "X_test_processed = preprocessor.transform(X_test)\n",
        "\n",
        "#fit the model\n",
        "logreg = LogisticRegression(max_iter=10000).fit(X_train_processed, y_train)\n",
        "\n",
        "print(\"Training set score: {:.3f}\".format(logreg.score(X_train_processed, y_train)))\n",
        "print(\"Test set score: {:.3f}\".format(logreg.score(X_test_processed, y_test)))\n",
        "print(classification_report(y_test, logreg.predict(X_test_processed),\n",
        "                            target_names=[\"no SMM\", \"SMM\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GY-QLhhFQ791"
      },
      "source": [
        "Using default settings, logistic regression predicted all births as having no maternal morbidity. Although this yields high accuracy because the outcome is rare, the model's recall for the positive class is zero. This confirms that the default model does not handle class imbalance well, which motivates the need for cross-validation and parameter tuning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nc5KwE4DgeZc"
      },
      "source": [
        "Random Forest:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vV9fd6k9ghbJ",
        "outputId": "add456bb-499a-49ce-b081-61a334535614"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on training set: 0.992\n",
            "Accuracy on test set: 0.983\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      no SMM       0.98      1.00      0.99   1071217\n",
            "         SMM       0.07      0.01      0.01     16691\n",
            "\n",
            "    accuracy                           0.98   1087908\n",
            "   macro avg       0.53      0.50      0.50   1087908\n",
            "weighted avg       0.97      0.98      0.98   1087908\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "forest = RandomForestClassifier(n_estimators=50,\n",
        "                                random_state=2,\n",
        "                                n_jobs=-1)\n",
        "forest.fit(X_train, y_train)\n",
        "\n",
        "# Classification Report\n",
        "\n",
        "print(\"Accuracy on training set: {:.3f}\".format(forest.score(X_train, y_train)))\n",
        "print(\"Accuracy on test set: {:.3f}\".format(forest.score(X_test, y_test)))\n",
        "print(classification_report(y_test, forest.predict(X_test),\n",
        "                            target_names=[\"no SMM\", \"SMM\"]))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KT8yzbpgic7"
      },
      "source": [
        "The default Random Forest model (50 trees) achieved very high overall accuracy (~0.98), but performance is driven entirely by the majority class. The model almost never predicts SMM cases: recall for SMM was only 0.01 and precision was 0.07. This behavior reflects the underlying class imbalance: without tuning, the Random Forest learns to return the majority class for nearly every case. Like logistic regression, the default model performs well on accuracy, but performs poorly on the minority outcome of interest."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzD76LaPHlzW"
      },
      "source": [
        "### Run with the default parameters using cross-validation on the training set. Calculate precision, recall, and F1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsqAmnvodkiL"
      },
      "source": [
        "Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCZxpDktHoh-",
        "outputId": "8f0ba2af-e0b7-4adc-845c-69420b12a07b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cv_scores:\n",
            "[0. 0. 0. 0. 0.]\n",
            "cv_scores mean:\n",
            "0.0\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Default logistic regression (max_iter increased only to ensure convergence)\n",
        "logreg_cv = LogisticRegression(max_iter=10000)\n",
        "\n",
        "# 5-fold cross validation on the processed training set, with a focus on minority class performance\n",
        "cv_scores = cross_val_score(\n",
        "    logreg_cv,\n",
        "    X_train_processed,\n",
        "    y_train,\n",
        "    cv=5,\n",
        "    scoring=\"f1\"\n",
        ")\n",
        "\n",
        "print(\"cv_scores:\\n{}\".format(cv_scores))\n",
        "print(\"cv_scores mean:\\n{}\".format(np.mean(cv_scores)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQ-BiahDeKD_"
      },
      "source": [
        "Using 5-fold cross-validation with default logistic regression, the F1 scores for the SMM class are 0 across all folds. This mirrors the test-set results, confirms that the default model consistently predicts only the majority class, and reinforces that I need to adjust the model to address the severe class imbalance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cf3h7RPAglIz"
      },
      "source": [
        "Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "HUShMggxgmkI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84c85878-da60-4fae-bb04-048140bc0ae3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cv_scores:\n",
            "[0.01184944 0.01160497 0.00973011 0.01003032 0.01191171]\n",
            "cv_scores mean:\n",
            "0.01102531042703915\n"
          ]
        }
      ],
      "source": [
        "#### NOTE this takes ~35 minutes to run ###\n",
        "forest_cv = RandomForestClassifier(n_estimators=50, random_state=2, n_jobs=-1)\n",
        "\n",
        "#5-fold cross validation\n",
        "cv_scores_forest = cross_val_score(\n",
        "    forest_cv,\n",
        "    X_train,\n",
        "    y_train,\n",
        "    cv=5,\n",
        "    scoring=\"f1\")\n",
        "\n",
        "print(\"cv_scores:\\n{}\".format(cv_scores_forest))\n",
        "print(\"cv_scores mean:\\n{}\".format(np.mean(cv_scores_forest)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MCAttVagnBr"
      },
      "source": [
        "The 5-fold cross-validation F1 scores were all very low (~0.01), with a mean F1 of 0.011, reinforcing that the default Random Forest model does not meaningfully detect SMM cases, even when evaluated across training folds. Like the default test-set performance, the model consistently predicts the majority class and therefore produces near-zero F1 scores for the minority outcome. Cross-validation reinforces that the model is stable, but ineffective for identifying rare SMM events without tuning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBQMY4uTHqMF"
      },
      "source": [
        "### Adjust 2-3 parameters for each model using grid search on the training set. Report evaluation metrics for the best and worst-performing parameter settings on your training set and your testing set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73c_HfZLd60p"
      },
      "source": [
        "Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3MzAPXS1d6gW"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# base model\n",
        "logreg_base = LogisticRegression(max_iter=10000)\n",
        "\n",
        "# Hyperparameter grid:\n",
        "# - C: regularization strength\n",
        "# - class_weight: whether to correct for class imbalance\n",
        "param_grid = {\n",
        "    \"C\": [0.01, 0.1, 1, 10],\n",
        "    \"class_weight\": [None, \"balanced\"]\n",
        "}\n",
        "\n",
        "# Grid search with 5-fold cross-validation\n",
        "logreg_grid = GridSearchCV(\n",
        "    estimator=logreg_base,\n",
        "    param_grid=param_grid,\n",
        "    cv=5,\n",
        "    scoring=\"f1\",\n",
        "    n_jobs=-1\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nc7-ErS7uowy"
      },
      "source": [
        "To tune the logistic regression model, I adjusted two hyperparameters that directly affect performance under extreme class imbalance:\n",
        "\n",
        "*   C : controls model flexibility. Lower values impose stronger regularization, which can cause logistic regression to predict only the majority class.\n",
        "*   class_weight: determines whether the algorithm should treat SMM and non-SMM cases as equally important. Setting \"balanced\" forces the model to up-weight the minority class and counter the severe imbalance in the data.\n",
        "\n",
        "\n",
        "I used a grid search with 5-fold cross-validation on the training set to evaluate combinations of these parameters using F1 as the scoring metric. I used F1 because it balances precision and recall and provides a more meaningful measure of minority-class performance than accuracy; however, if I were optimizing solely for SMM detection, I would tune for recall, which prioritizes sensitivity over precision."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjaNtC_00IeV"
      },
      "source": [
        "**Best Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLAVVaxviizQ",
        "outputId": "dcb37f93-fa57-4b72-8354-0a1d251f27ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best parameters: {'C': 0.1, 'class_weight': 'balanced'}\n",
            "Best mean CV F1: 0.04438632858767309\n",
            "\n",
            "=== Best Logistic Regression – Training Set ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      0.60      0.75   2499504\n",
            "         1.0       0.02      0.60      0.04     38946\n",
            "\n",
            "    accuracy                           0.60   2538450\n",
            "   macro avg       0.51      0.60      0.40   2538450\n",
            "weighted avg       0.97      0.60      0.74   2538450\n",
            "\n",
            "\n",
            "=== Best Logistic Regression – Test Set ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      0.61      0.75   1071217\n",
            "         1.0       0.02      0.60      0.04     16691\n",
            "\n",
            "    accuracy                           0.61   1087908\n",
            "   macro avg       0.51      0.60      0.40   1087908\n",
            "weighted avg       0.98      0.61      0.74   1087908\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "### NOTE this takes ~25 minutes to run ###\n",
        "\n",
        "# best parameters\n",
        "logreg_grid.fit(X_train_processed, y_train)\n",
        "\n",
        "print(\"Best parameters:\", logreg_grid.best_params_)\n",
        "print(\"Best mean CV F1:\", logreg_grid.best_score_)\n",
        "\n",
        "# Best model (refit on full training set by GridSearchCV)\n",
        "best_logreg = logreg_grid.best_estimator_\n",
        "\n",
        "# ---- Evaluate best model on TRAINING and TEST sets ----\n",
        "print(\"\\n=== Best Logistic Regression – Training Set ===\")\n",
        "print(classification_report(y_train, best_logreg.predict(X_train_processed)))\n",
        "\n",
        "print(\"\\n=== Best Logistic Regression – Test Set ===\")\n",
        "print(classification_report(y_test, best_logreg.predict(X_test_processed)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-y6NsiUxw7i"
      },
      "source": [
        "**Best Parameters: (C = 0.1, class_weight = \"balanced\")**\n",
        "\n",
        "This combination produced the strongest performance on the training set. Class weighting shifted the model away from majority-class dominance, and toward identifying SMM cases. The moderate regularization (C = 0.1) allowed the model to adjust without overfitting the data.\n",
        "\n",
        "With these parameters, the model began predicting some SMM cases rather than collapsing to all zeros. Recall for SMM increased dramatically (≈ 0.60), meaning the model captured about 60% of true SMM events, as compared to 0% using the default parameters.\n",
        "\n",
        "Precision for SMM remained low (≈ 0.02), which is expected when predicting a rare outcome. Overall accuracy fell to ~0.60, reflecting the shift toward detecting minority-class cases rather than maximizing accuracy.\n",
        "\n",
        "This model does not produce strong clinical predictions, but it does respond meaningfully to the imbalance-aware tuning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chI-OMbT0Vav"
      },
      "source": [
        "**Worst Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbnoWr6bi2zg",
        "outputId": "52c75017-8af2-408c-ebc0-409d7a5f73e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Worst parameters: {'C': 0.01, 'class_weight': None}\n",
            "Worst mean CV F1: 0.0\n",
            "\n",
            "=== Worst Logistic Regression – Training Set ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      1.00      0.99   2499504\n",
            "         1.0       0.00      0.00      0.00     38946\n",
            "\n",
            "    accuracy                           0.98   2538450\n",
            "   macro avg       0.49      0.50      0.50   2538450\n",
            "weighted avg       0.97      0.98      0.98   2538450\n",
            "\n",
            "\n",
            "=== Worst Logistic Regression – Test Set ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      1.00      0.99   1071217\n",
            "         1.0       0.00      0.00      0.00     16691\n",
            "\n",
            "    accuracy                           0.98   1087908\n",
            "   macro avg       0.49      0.50      0.50   1087908\n",
            "weighted avg       0.97      0.98      0.98   1087908\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "# worst parameters\n",
        "cv_results = logreg_grid.cv_results_\n",
        "mean_f1 = cv_results[\"mean_test_score\"]\n",
        "worst_index = np.argmin(mean_f1)\n",
        "worst_params = cv_results[\"params\"][worst_index]\n",
        "\n",
        "print(\"\\nWorst parameters:\", worst_params)\n",
        "print(\"Worst mean CV F1:\", mean_f1[worst_index])\n",
        "\n",
        "# Refit a model using the worst parameters\n",
        "worst_logreg = LogisticRegression(max_iter=10000, **worst_params)\n",
        "worst_logreg.fit(X_train_processed, y_train)\n",
        "\n",
        "print(\"\\n=== Worst Logistic Regression – Training Set ===\")\n",
        "print(classification_report(y_train, worst_logreg.predict(X_train_processed)))\n",
        "\n",
        "print(\"\\n=== Worst Logistic Regression – Test Set ===\")\n",
        "print(classification_report(y_test, worst_logreg.predict(X_test_processed)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_Y6qK9bgQuk"
      },
      "source": [
        "**Worst Parameters (C = 0.01, class_weight = None)**\n",
        "\n",
        "In this model, stronger regularization (C = 0.01) and no class weighting defaulted to predicting the majority class exclusively. Without class weighting, the model is heavily biased toward predicting the majority class.\n",
        "\n",
        "This model predicted zero SMM cases in both the training and test sets. Recall and precision for SMM fell to 0, and the F1 score remained at 0 across all folds. Accuracy stayed artificially high (~0.98) simply because almost all births do not involve SMM. However, this accuracy is not meaningful because the model is unable to detect the minority class at all.\n",
        "\n",
        "**Model Comparison**\n",
        "\n",
        "Parameter tuning fundamentally changed the behavior of the logistic regressions.\n",
        "Adding class weights and adjusting regularization shifted the model from predicting only the majority class to identifying a meaningful proportion of SMM cases, even though precision remained low. These patterns mirror real-world challenges when modeling rare clinical outcomes and illustrate how tuning alters model behavior under severe class imbalance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlN9RLS7gS-4"
      },
      "source": [
        "Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "zOHM369-HwDv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "589c011e-d84d-43ad-f3c2-e224ebafc3be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, estimator=RandomForestClassifier(n_jobs=-1, random_state=2),\n",
              "             n_jobs=-1,\n",
              "             param_grid={'max_depth': [None, 5, 10],\n",
              "                         'max_features': ['sqrt', 'log2'],\n",
              "                         'n_estimators': [20, 50, 100]},\n",
              "             scoring='f1')"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=RandomForestClassifier(n_jobs=-1, random_state=2),\n",
              "             n_jobs=-1,\n",
              "             param_grid={&#x27;max_depth&#x27;: [None, 5, 10],\n",
              "                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
              "                         &#x27;n_estimators&#x27;: [20, 50, 100]},\n",
              "             scoring=&#x27;f1&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=3, estimator=RandomForestClassifier(n_jobs=-1, random_state=2),\n",
              "             n_jobs=-1,\n",
              "             param_grid={&#x27;max_depth&#x27;: [None, 5, 10],\n",
              "                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
              "                         &#x27;n_estimators&#x27;: [20, 50, 100]},\n",
              "             scoring=&#x27;f1&#x27;)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: RandomForestClassifier</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(max_features=&#x27;log2&#x27;, n_estimators=20, n_jobs=-1,\n",
              "                       random_state=2)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(max_features=&#x27;log2&#x27;, n_estimators=20, n_jobs=-1,\n",
              "                       random_state=2)</pre></div> </div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# Subsample of training data for tuning\n",
        "X_train_sub, _, y_train_sub, _ = train_test_split(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    train_size=0.2,\n",
        "    stratify=y_train,\n",
        "    random_state=66\n",
        ")\n",
        "\n",
        "# base model\n",
        "rf_base = RandomForestClassifier(random_state=2, n_jobs=-1)\n",
        "\n",
        "#parameter grid\n",
        "param_grid_rf = {\n",
        "    \"n_estimators\": [20, 50, 100],\n",
        "    \"max_depth\": [None, 5, 10],\n",
        "    \"max_features\": [\"sqrt\", \"log2\"]\n",
        "}\n",
        "\n",
        "#grid search-- CV dropped to 3 for runtime concerns\n",
        "rf_grid = GridSearchCV(\n",
        "    estimator=rf_base,\n",
        "    param_grid=param_grid_rf,\n",
        "    scoring=\"f1\",\n",
        "    cv=3,      # reduce from 5 to 3 for speed\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "rf_grid.fit(X_train_sub, y_train_sub)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQgQbaCfgWDY"
      },
      "source": [
        "To adjust the Random Forest model, I used three parameters that directly influence model flexibility and performance:\n",
        "\n",
        "*   n_estimators: the number of trees in the forest. While more trees stabilize predictions, they increase computation time.\n",
        "*   max_depth: the maximum depth of each tree. Shallow trees reduce overfitting, while deeper trees allow the model to learn more complex patterns.\n",
        "*   max_features: the number of predictors considered at each split\n",
        "\n",
        "Due to the size of the training set, I used a stratified 20% subsample of the training data for tuning. The subsample preserves class balance and allows meaningful comparison across parameter combinations, while keeping the grid search computationally feasible in Colab. I performed a grid search with 3-fold cross-validation and used F1 score as the evaluation metric to prioritize performance on the minority SMM class."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Best Model**"
      ],
      "metadata": {
        "id": "0UVcn0jgCsyx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# extract best performing parameter combination\n",
        "best_rf = rf_grid.best_estimator_\n",
        "\n",
        "print(\"Best params:\", rf_grid.best_params_)\n",
        "print(\"Best CV F1:\", rf_grid.best_score_)\n",
        "\n",
        "print(\"\\n=== Best RF – Training Set ===\")\n",
        "print(classification_report(y_train, best_rf.predict(X_train),\n",
        "                            target_names=[\"no SMM\", \"SMM\"]))\n",
        "\n",
        "print(\"\\n=== Best RF – Test Set ===\")\n",
        "print(classification_report(y_test, best_rf.predict(X_test),\n",
        "                            target_names=[\"no SMM\", \"SMM\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_Sy8EwFC04R",
        "outputId": "144f0aa8-81c7-4f7e-f8ea-3c88129fb5e4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best params: {'max_depth': None, 'max_features': 'log2', 'n_estimators': 20}\n",
            "Best CV F1: 0.007577080829456889\n",
            "\n",
            "=== Best RF – Training Set ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      no SMM       0.99      1.00      0.99   2499504\n",
            "         SMM       0.56      0.12      0.19     38946\n",
            "\n",
            "    accuracy                           0.99   2538450\n",
            "   macro avg       0.77      0.56      0.59   2538450\n",
            "weighted avg       0.98      0.99      0.98   2538450\n",
            "\n",
            "\n",
            "=== Best RF – Test Set ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      no SMM       0.98      1.00      0.99   1071217\n",
            "         SMM       0.04      0.00      0.01     16691\n",
            "\n",
            "    accuracy                           0.98   1087908\n",
            "   macro avg       0.51      0.50      0.50   1087908\n",
            "weighted avg       0.97      0.98      0.98   1087908\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Best Parameters (max_depth = None, max_features = \"log2\", n_estimators = 20)**\n",
        "\n",
        "The parameter combination that performed best on the subsampled training set (F1 = 0.0076) used 20 trees, unlimited depth, and log2 feature sampling. Allowing unlimited tree depth (max_depth=None) and using log2 feature sampling increased model flexibility.\n",
        "\n",
        "When evaluated on the full training set, the tuned model showed clear signs of overfitting: SMM recall increased to 0.12 and SMM F1 rose to 0.19, but this performance did not generalize. On the test set, SMM recall dropped to essentially zero (0.00), with precision at 0.04 and F1 at 0.01. Despite tuning, the model reverted to predicting almost exclusively the majority class.\n",
        "\n",
        "Even under its best parameter settings, the Random Forest was unable to learn generalizable patterns for SMM prediction. Tuning increased model flexibility, but the underlying class imbalance prevented the model from capturing the rare SMM cases effectively."
      ],
      "metadata": {
        "id": "9PD96ZaOC7fl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Worst Model**"
      ],
      "metadata": {
        "id": "qMSN0fheC-R6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# extract worst performing parameter combination\n",
        "cv_results = rf_grid.cv_results_\n",
        "mean_f1 = cv_results[\"mean_test_score\"]\n",
        "worst_idx = mean_f1.argmin()\n",
        "worst_params = cv_results[\"params\"][worst_idx]\n",
        "\n",
        "print(\"Worst params:\", worst_params)\n",
        "print(\"Worst CV F1:\", mean_f1[worst_idx])\n",
        "\n",
        "# Refit worst model on full training data\n",
        "rf_worst = RandomForestClassifier(\n",
        "    **worst_params,\n",
        "    random_state=2,\n",
        "    n_jobs=-1\n",
        ").fit(X_train, y_train)\n",
        "\n",
        "print(\"\\n=== Worst RF – Training Set ===\")\n",
        "print(classification_report(y_train, rf_worst.predict(X_train),\n",
        "                            target_names=[\"no SMM\", \"SMM\"]))\n",
        "\n",
        "print(\"\\n=== Worst RF – Test Set ===\")\n",
        "print(classification_report(y_test, rf_worst.predict(X_test),\n",
        "                            target_names=[\"no SMM\", \"SMM\"]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Fm4-_RmDF3j",
        "outputId": "d03e3206-e191-478f-a4a3-4657f6effda6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Worst params: {'max_depth': 5, 'max_features': 'sqrt', 'n_estimators': 20}\n",
            "Worst CV F1: 0.0\n",
            "\n",
            "=== Worst RF – Training Set ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      no SMM       0.98      1.00      0.99   2499504\n",
            "         SMM       0.00      0.00      0.00     38946\n",
            "\n",
            "    accuracy                           0.98   2538450\n",
            "   macro avg       0.49      0.50      0.50   2538450\n",
            "weighted avg       0.97      0.98      0.98   2538450\n",
            "\n",
            "\n",
            "=== Worst RF – Test Set ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      no SMM       0.98      1.00      0.99   1071217\n",
            "         SMM       0.00      0.00      0.00     16691\n",
            "\n",
            "    accuracy                           0.98   1087908\n",
            "   macro avg       0.49      0.50      0.50   1087908\n",
            "weighted avg       0.97      0.98      0.98   1087908\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Worst Parameters (max_depth = 5, max_features = \"sqrt\", n_estimators = 20)**\n",
        "\n",
        "The worst-performing configuration used 20 trees with a maximum depth of 5 and sqrt feature sampling. This combination produced a cross-validated F1 score of 0.0 on the subsampled training set.\n",
        "\n",
        "When evaluated on the full training and test sets, the model predicted only the majority class. SMM precision, recall, and F1 all dropped to 0. Overall the model reports an accuracy of approximately 0.98, but this accuracy is not meaningful because the model fails to identify any SMM cases. Restricting tree depth prevented the model from capturing even weak patterns associated with the minority class.\n",
        "\n",
        "This configuration demonstrates how reducing model complexity can cause Random Forests to collapse entirely under severe class imbalance, defaulting to majority-class predictions and losing any ability to detect rare events.\n",
        "\n",
        "\n",
        "**Model Comparison**\n",
        "\n",
        "Across all tuned configurations, the Random Forest struggled to learn generalizable patterns for the rare SMM outcome. The best model showed modest improvement in SMM recall on the full training set, but this gain disappeared on the test set-- clear evidence of overfitting.\n",
        "\n",
        "The worst model, with shallow trees and limited feature sampling, predicted only the majority class and returned zero recall for SMM.\n",
        "\n",
        "Overall, tuning changed the model's behavior, but did not overcome the severe class imbalance. As with logistic regression, Random Forest performance remained dominated by the majority class, underscoring the difficulty of predicting rare clinical events without additional imbalance-handling techniques."
      ],
      "metadata": {
        "id": "0kMYLfKLDXFc"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOZxQhRvQHwnDsrl+bt/uU5",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}